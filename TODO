do we need to have two layers of mlp in the yatformer attention block?
